{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from load_data import load_data\n",
    "import torch\n",
    "from modules import GNN\n",
    "from train_model import train_model\n",
    "from subgraph_relevance import subgraph_original, subgraph_mp_transcription, subgraph_mp_forward_hook, get_H_transform\n",
    "from utils import create_ground_truth, get_feat_order_local_best_guess, get_auac_aupc, get_stats\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, pos_idx, neg_idx = load_data('BA-2motif')\n",
    "\n",
    "model_dirs = ['gin-2-ba2motif.torch',\n",
    "            'gin-3-ba2motif.torch',\n",
    "            'gin-4-ba2motif.torch',\n",
    "            'gin-5-ba2motif.torch',\n",
    "            'gin-6-ba2motif.torch',\n",
    "            'gin-7-ba2motif.torch']\n",
    "\n",
    "g = graphs[44]\n",
    "S = [0,1,2,3]\n",
    "alpha = 0.\n",
    "verbose = False\n",
    "num_samples = 50\n",
    "sample_idx = np.random.choice(len(graphs),num_samples,replace=False)\n",
    "\n",
    "model_times = []\n",
    "\n",
    "nn = torch.load('models/'+model_dirs[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNNExplainer\n",
    "from GNN-LRP git repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigm(z):\n",
    "    return torch.tanh(0.5*z)*0.5+0.5\n",
    "\n",
    "def gnnexplainer(g,nn,H0=None,steps=500,lr=0.5,lambd=0.01,verbose=False):\n",
    "    z = torch.ones(g.get_adj().shape)*g.get_adj()*2\n",
    "    num_layer = len(nn.blocks) -1\n",
    "    for i in range(steps):\n",
    "        z.requires_grad_(True)\n",
    "\n",
    "        score = nn.forward(g.get_adj(),H0=H0,masks=[sigm(z)]*num_layer)[g.label] # ,sigm(z)\n",
    "        emp   = -score\n",
    "        reg   = lambd*((z)**2).sum() # torch.zeros((1,))   \n",
    "\n",
    "        if i in [j**3 for j in range(100)] and verbose: print('%5d %8.3f %8.3f'%(i,emp.item(),reg.item()))\n",
    "\n",
    "        (emp+reg).backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = (z - lr*z.grad)\n",
    "        z.grad = None\n",
    "\n",
    "    return z.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gnnexplainer -> Scores for every edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = gnnexplainer(g, nn, verbose=True)\n",
    "\n",
    "def get_fo_gnnexpl(R, alpha=0, mode='extr'):\n",
    "    node_order = []\n",
    "    node_set = set(range(R.shape[0]))\n",
    "\n",
    "    for i in range(R.shape[0]):\n",
    "        max_node = None\n",
    "        max_score = -float('inf')\n",
    "        for node in node_set:\n",
    "            subgraph = node_order + [node]\n",
    "            mask = torch.zeros(R.shape)\n",
    "            mask[subgraph, :] = alpha\n",
    "            mask[:, subgraph] = alpha\n",
    "            mask[subgraph, subgraph] = 1\n",
    "            score = (mask * R).sum()\n",
    "            if mode == 'prun':\n",
    "                score = -score\n",
    "            if score > max_score:\n",
    "                max_node = node\n",
    "                max_score = score\n",
    "        node_order.append(max_node)\n",
    "        node_set -= {max_node}\n",
    "\n",
    "    return node_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-based heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fo_gb(nn, g, mode='extr'):\n",
    "    if g.node_features is not None:\n",
    "        H0 = g.node_features\n",
    "    else:\n",
    "        H0 = torch.ones([g.get_adj().shape[0],1])\n",
    "    H0.requires_grad_()\n",
    "    score = nn.forward(g.get_adj(),H0)[g.label]\n",
    "\n",
    "    score.backward()\n",
    "    if mode == 'extr':\n",
    "        node_order = H0.grad.sum(axis=1).abs().flatten().argsort(descending=True)\n",
    "    else:\n",
    "        node_order = H0.grad.sum(axis=1).abs().flatten().argsort(descending=False)\n",
    "        \n",
    "    return node_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAM & Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAM(nn,A,H0=None,masks=None):\n",
    "    \n",
    "    if masks is None:\n",
    "        masks = [1]*(len(nn.blocks)-1)\n",
    "    H0 = nn.ini(A, H0)\n",
    "\n",
    "    H = nn.blocks[0].forward(H0,torch.eye(H0.shape[0]).unsqueeze(0))\n",
    "\n",
    "    A = nn.adj(A)\n",
    "\n",
    "    for l,mask in zip(nn.blocks[1:],masks):\n",
    "        H = l.forward(H,A,mask=mask)\n",
    "\n",
    "    # H = H.sum(dim=0) / 20**.5\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fo_cam(nn, g, mode='extr'):\n",
    "    if mode == 'extr':\n",
    "        return CAM(nn, g.get_adj(), g.node_features)[:,g.label].abs().argsort(descending=True)\n",
    "    else:\n",
    "        return CAM(nn, g.get_adj(), g.node_features)[:,g.label].abs().argsort(descending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC etc. experiments\n",
    "\n",
    "Comment and uncomment to run different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "test_samples = 200\n",
    "\n",
    "# BA-2motif\n",
    "# dataset = 'BA-2motif'\n",
    "# graphs, pos_idx, neg_idx = load_data('BA-2motif')\n",
    "# model_dir = \"models/gin-3-ba2motif.torch\"; num_layer= 3\n",
    "# nn = torch.load(model_dir)\n",
    "\n",
    "# # MUTAG\n",
    "dataset = 'MUTAG'\n",
    "graphs, pos_idx, neg_idx = load_data('MUTAG')\n",
    "model_dir = \"models/gin-3-mutag.torch\"; num_layer= 3\n",
    "nn = torch.load(model_dir)\n",
    "\n",
    "# # Graph-SST2\n",
    "# dataset = 'Graph-SST2'\n",
    "# graphs, pos_idx, neg_idx = load_data('Graph-SST2')\n",
    "# model_dir = \"models/gcn-3-sst2graph.torch\"; num_layer= 3\n",
    "# nn = torch.load(model_dir)\n",
    "\n",
    "message = '{}\\nModel depth: {}, model: {}, nb of samples: {}\\n'.format(model_dir,num_layer, 'gin', test_samples)\n",
    "print(message)\n",
    "\n",
    "messages = []\n",
    "# test_sample_idx = [] # quote out when running for the same samples for aupc/auac\n",
    "alpha_stats = {}\n",
    "for alpha in tqdm(np.arange(0.0,1.01,0.05)):\n",
    "    if dataset == 'BA-2motif':\n",
    "        stats = {}\n",
    "        stats['GNNExplainer'] = {'acc': [], 'auc': [], 'auac': [], 'aupc': [], 'acs': [], 'pcs': [], 'label': []}\n",
    "        stats['Gradient-based'] = {'acc': [], 'auc': [], 'auac': [], 'aupc': [], 'acs': [], 'pcs': [], 'label': []}\n",
    "        stats['CAM'] = {'acc': [], 'auc': [], 'auac': [], 'aupc': [], 'acs': [], 'pcs': [], 'label': []}\n",
    "    else:\n",
    "        stats = {}\n",
    "        stats['GNNExplainer'] = {'auac_pos': [], 'aupc_pos': [], 'auac_neg': [], 'aupc_neg': []}\n",
    "        stats['Gradient-based'] = {'auac_pos': [], 'aupc_pos': [], 'auac_neg': [], 'aupc_neg': []}\n",
    "        stats['CAM'] = {'auac_pos': [], 'aupc_pos': [], 'auac_neg': [], 'aupc_neg': []}\n",
    "    cnt_pos = test_samples / 2\n",
    "    cnt_neg = test_samples / 2\n",
    "    start = time.time()\n",
    "    random_sample = True if test_sample_idx == [] else False\n",
    "    i = 0\n",
    "    while cnt_pos > 0 or cnt_neg > 0:\n",
    "        if random_sample:\n",
    "            idx = np.random.randint(len(graphs))\n",
    "            g = graphs[idx]\n",
    "            if g.nbnodes < 3: continue\n",
    "            if g.label == 0:\n",
    "                if cnt_pos == 0: continue\n",
    "                else: cnt_pos -= 1\n",
    "            else:\n",
    "                if cnt_neg == 0: continue\n",
    "                else: cnt_neg -= 1\n",
    "            test_sample_idx.append(idx)\n",
    "        else:\n",
    "            if i >= len(test_sample_idx): break\n",
    "            g = graphs[test_sample_idx[i]]\n",
    "            i += 1\n",
    "\n",
    "        gr_tr, all_feats = create_ground_truth(g)\n",
    "\n",
    "        mode = 'prun'\n",
    "        # mode = 'extr'\n",
    "\n",
    "        # H, transforms = get_H_transform(g.get_adj(),nn,gammas=None)\n",
    "        # fo = get_feat_order_local_best_guess(nn, g, alpha, H, transforms, mode='extr')\n",
    "\n",
    "        for method in ['GNNExplainer', 'Gradient-based', 'CAM']:\n",
    "            if method == 'GNNExplainer':\n",
    "                R = gnnexplainer(g, nn, H0=g.node_features, verbose=False)\n",
    "                fo = get_fo_gnnexpl(R, alpha, mode)\n",
    "            elif method == 'Gradient-based':\n",
    "                fo = get_fo_gb(nn, g, mode)\n",
    "            elif method == 'CAM':\n",
    "                fo = get_fo_cam(nn, g, mode)\n",
    "            \n",
    "            nb_nodes = g.get_adj().shape[0]\n",
    "            best_fo = torch.full((nb_nodes,), -1)\n",
    "            for ii, fs in enumerate(fo):\n",
    "                best_fo[fs] = nb_nodes - ii\n",
    "            fo = best_fo\n",
    "\n",
    "            if mode == 'extr':\n",
    "                if dataset == 'BA-2motif':\n",
    "                    acc, auc = get_stats(gr_tr, fo, all_feats)\n",
    "                else:\n",
    "                    auac, acs = get_auac_aupc(nn, g, fo, task=mode, use_softmax=False)\n",
    "                    aupc, pcs = [], []\n",
    "            else:\n",
    "                if dataset == 'BA-2motif':\n",
    "                    acc, auc = [], []\n",
    "                else:\n",
    "                    aupc, pcs = get_auac_aupc(nn, g, fo, task=mode, use_softmax=False)\n",
    "                    auac, acs = [], []\n",
    "\n",
    "            if dataset == 'BA-2motif':\n",
    "                stats[method]['acc'].append(acc)\n",
    "                stats[method]['auc'].append(auc)\n",
    "            else:\n",
    "                if g.label == 0:\n",
    "                    stats[method]['auac_pos'].append(auac)\n",
    "                    stats[method]['aupc_pos'].append(aupc)\n",
    "                else:\n",
    "                    stats[method]['auac_neg'].append(auac)\n",
    "                    stats[method]['aupc_neg'].append(aupc)\n",
    "                # stats[method]['acs'].append(acs)\n",
    "                # stats[method]['pcs'].append(pcs)\n",
    "            # stats[method]['label'].append(g.label)\n",
    "    for method in stats.keys():\n",
    "        for key in stats[method].keys():\n",
    "            stats[method][key] = np.mean(stats[method][key])\n",
    "    alpha_stats[alpha] = stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_df = pd.DataFrame(columns=['method','auac_pos','auac_neg','alpha'])\n",
    "stat_df = pd.DataFrame(columns=['method','aupc_pos','aupc_neg','alpha'])\n",
    "\n",
    "for alpha, stat in zip(alpha_stats.keys(), alpha_stats.values()):\n",
    "    # print(alpha,stat)\n",
    "    # df = pd.DataFrame(stat).T[['auac_pos','auac_neg']]\n",
    "    df = pd.DataFrame(stat).T[['aupc_pos','aupc_neg']]\n",
    "    df['alpha'] = alpha\n",
    "    df['method'] = df.index\n",
    "    stat_df = stat_df.append(df)\n",
    "stat_df = stat_df.reset_index(drop=True)\n",
    "stat_df.to_csv('evaluation_results/gnnexpl_etc_aupc_mutag.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df = pd.DataFrame(columns=['method','acc','auc','alpha'])\n",
    "for alpha, stat in zip(alpha_stats.keys(), alpha_stats.values()):\n",
    "    # print(alpha,stat)\n",
    "    df = pd.DataFrame(stat).T[['acc','auc']]\n",
    "    df['alpha'] = alpha\n",
    "    df['method'] = df.index\n",
    "    stat_df = stat_df.append(df)\n",
    "stat_df = stat_df.reset_index(drop=True)\n",
    "stat_df.to_csv('evaluation_results/gnnexpl_etc_ba2motif.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'BA-2motif'\n",
    "graphs, pos_idx, neg_idx = load_data('BA-2motif')\n",
    "model_dir = \"models/gin-3-ba2motif.torch\"; num_layer= 3\n",
    "nn = torch.load(model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "sample_idx = np.random.choice(len(graphs),num_samples,replace=False)\n",
    "\n",
    "masks = None\n",
    "alpha = 0.5\n",
    "time_stats = []\n",
    "\n",
    "model_dirs = ['gin-2-ba2motif.torch',\n",
    "            'gin-3-ba2motif.torch',\n",
    "            'gin-4-ba2motif.torch',\n",
    "            'gin-5-ba2motif.torch',\n",
    "            'gin-6-ba2motif.torch',\n",
    "            'gin-7-ba2motif.torch']\n",
    "\n",
    "# for i in tqdm(range(1, 26)):\n",
    "for model in tqdm(model_dirs):\n",
    "    nn = torch.load(\"models/\"+model)\n",
    "    subgraph = np.arange(5)\n",
    "    time_ll = []\n",
    "    for idx in sample_idx:\n",
    "        time_l = []\n",
    "        g = graphs[idx]\n",
    "        H0 = g.node_features\n",
    "\n",
    "        # naive GNN-LRP\n",
    "        time_a = time.time()\n",
    "        score_naive_gnnlrp = subgraph_original(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        time_l.append(time.time()-time_a)\n",
    "\n",
    "        # sGNN-LRP\n",
    "        time_a = time.time()\n",
    "        score_sgnnlrp = subgraph_mp_forward_hook(nn, g, subgraph, alpha,)\n",
    "        time_l.append(time.time()-time_a)\n",
    "\n",
    "        # GNNExplainer\n",
    "        time_a = time.time()\n",
    "        R = gnnexplainer(g, nn, verbose=False)\n",
    "        node_order = []\n",
    "        node_set = set(range(R.shape[0]))\n",
    "\n",
    "        mask = torch.zeros(R.shape)\n",
    "        mask[subgraph, :] = alpha\n",
    "        mask[:, subgraph] = alpha\n",
    "        mask[subgraph, subgraph] = 1\n",
    "        score_gnnexpl = (mask * R).sum()\n",
    "\n",
    "        time_l.append(time.time()-time_a)\n",
    "\n",
    "        # Gradient\n",
    "        time_a = time.time()\n",
    "        if g.node_features is not None:\n",
    "            H0 = g.node_features\n",
    "        else:\n",
    "            H0 = torch.ones([g.get_adj().shape[0],1])\n",
    "        H0.requires_grad_()\n",
    "        score = nn.forward(g.get_adj(),H0)[g.label]\n",
    "        score.backward()\n",
    "        score_grad = H0.grad.sum(axis=1).abs()[subgraph].sum()\n",
    "\n",
    "        time_l.append(time.time()-time_a)\n",
    "\n",
    "        # CAM\n",
    "        time_a = time.time()\n",
    "        if masks is None:\n",
    "            masks = [1]*(len(nn.blocks)-1)\n",
    "        H0 = nn.ini(g.get_adj(), H0)\n",
    "        H = nn.blocks[0].forward(H0,torch.eye(H0.shape[0]).unsqueeze(0))\n",
    "        A = nn.adj(g.get_adj())\n",
    "        for l,mask in zip(nn.blocks[1:],masks):\n",
    "            H = l.forward(H,A,mask=mask)\n",
    "        # H = H.sum(dim=0) / 20**.5\n",
    "        score_cam = H[subgraph, g.label].abs().sum().data\n",
    "\n",
    "        time_l.append(time.time()-time_a)\n",
    "        time_ll.append(time_l)\n",
    "    time_stats.append([int(model.split('-')[1])] + np.array(time_ll).mean(axis=0).tolist())\n",
    "time_stats_df = pd.DataFrame(time_stats, columns=['model_depth','naive', 'sGNN-LRP','GNNExplainer','Grad','CAM'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, gridspec_kw={'height_ratios': [2, 1, 1]}, figsize=(3.5,4))\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between axes\n",
    "ax1.yaxis.set_label_position(\"left\")\n",
    "\n",
    "plt.rc('legend', fontsize=12)\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['bottom'].set_visible(False)\n",
    "ax3.spines['top'].set_visible(False)\n",
    "\n",
    "ax3.set_xlabel(r'$L$')\n",
    "\n",
    "line1, = ax1.plot(time_stats_df['model_depth'], time_stats_df['naive'], 'm:')\n",
    "line2, = ax1.plot(time_stats_df['model_depth'], time_stats_df['sGNN-LRP'], 'r-')\n",
    "line3, = ax1.plot(time_stats_df['model_depth'], time_stats_df['Grad'], 'b--')\n",
    "line4, = ax1.plot(time_stats_df['model_depth'], time_stats_df['CAM'], 'y-.')\n",
    "line5, = ax1.plot(time_stats_df['model_depth'], time_stats_df['GNNExplainer'], 'g-+')\n",
    "ax1.legend(['naive GNN-LRP', 'sGNN-LRP', 'Gradient-based', '(Grad-)CAM', 'GNNExplainer'])\n",
    "\n",
    "line2.remove()\n",
    "line3.remove()\n",
    "line4.remove()\n",
    "line5.remove()\n",
    "\n",
    "ax2.plot(time_stats_df['model_depth'], time_stats_df['GNNExplainer'], 'g-+')\n",
    "ax2.plot(time_stats_df['model_depth'], time_stats_df['naive'], 'm:')\n",
    "\n",
    "ax2.set_ylabel('Time (s)')\n",
    "ax3.plot(time_stats_df['model_depth'], time_stats_df['naive'], 'm:')\n",
    "ax3.plot(time_stats_df['model_depth'], time_stats_df['sGNN-LRP'], 'r-')\n",
    "ax3.plot(time_stats_df['model_depth'], time_stats_df['Grad'], 'b--')\n",
    "ax3.plot(time_stats_df['model_depth'], time_stats_df['CAM'], 'y-.')\n",
    "\n",
    "\n",
    "ax1.spines.bottom.set_visible(False)\n",
    "ax3.spines.top.set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "\n",
    "ax1.xaxis.set_visible(False)\n",
    "ax2.xaxis.set_visible(False)\n",
    "ax2.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "\n",
    "ax1.set_ylim(2)\n",
    "ax2.set_ylim(0.004,0.7)  # outliers only\n",
    "ax3.set_ylim(-0,0.004)\n",
    "\n",
    "d = .5  # proportion of vertical to horizontal extent of the slanted line\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12,\n",
    "              linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "ax1.plot([0, 1], [0, 0], transform=ax1.transAxes, **kwargs)\n",
    "ax2.plot([0, 1], [1, 1], transform=ax2.transAxes, **kwargs)\n",
    "ax2.plot([0, 1], [0, 0], transform=ax2.transAxes, **kwargs)\n",
    "ax3.plot([0, 1], [1, 1], transform=ax3.transAxes, **kwargs)\n",
    "plt.savefig('imgs/time_consumption_gnnexpl_etc.eps', dpi=600, format='eps', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### |S| dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = g.node_features\n",
    "masks = None\n",
    "alpha = 0.5\n",
    "time_stats = []\n",
    "\n",
    "model_dirs = ['gin-3-ba2motif.torch']\n",
    "model = model_dirs[0]\n",
    "# for i in tqdm(range(1, 26)):\n",
    "# for model in tqdm(model_dirs):\n",
    "for _ in range(10):\n",
    "    time_l = []\n",
    "\n",
    "    time_a = time.time()\n",
    "\n",
    "    # sGNN-LRP\n",
    "    score_sgnnlrp = subgraph_mp_forward_hook(nn, g, subgraph, alpha,)\n",
    "\n",
    "    time_l.append(time.time()-time_a)\n",
    "    time_a = time.time()\n",
    "\n",
    "for s_size in tqdm(range(1,25)):\n",
    "    subgraph = np.arange(s_size)\n",
    "    nn = torch.load(\"models/\"+model)\n",
    "    time_ll = []\n",
    "    for _ in range(10):\n",
    "        time_l = []\n",
    "\n",
    "        # naive GNN-LRP\n",
    "        time_a = time.time()\n",
    "        score_naive_gnnlrp = subgraph_original(nn, g, subgraph, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        time_l.append(time.time()-time_a)\n",
    "\n",
    "        # sGNN-LRP\n",
    "        time_a = time.time()\n",
    "        score_sgnnlrp = subgraph_mp_forward_hook(nn, g, subgraph, alpha,)\n",
    "        time_l.append(time.time()-time_a)\n",
    "\n",
    "        # GNNExplainer\n",
    "        time_a = time.time()\n",
    "        R = gnnexplainer(g, nn, verbose=False)\n",
    "        node_order = []\n",
    "        node_set = set(range(R.shape[0]))\n",
    "\n",
    "        mask = torch.zeros(R.shape)\n",
    "        mask[subgraph, :] = alpha\n",
    "        mask[:, subgraph] = alpha\n",
    "        mask[subgraph, subgraph] = 1\n",
    "        score_gnnexpl = (mask * R).sum()\n",
    "\n",
    "        time_l.append(time.time()-time_a)\n",
    "\n",
    "        # Gradient\n",
    "        time_a = time.time()\n",
    "        if g.node_features is not None:\n",
    "            H0 = g.node_features\n",
    "        else:\n",
    "            H0 = torch.ones([g.get_adj().shape[0],1])\n",
    "        H0.requires_grad_()\n",
    "        score = nn.forward(g.get_adj(),H0)[g.label]\n",
    "        score.backward()\n",
    "        score_grad = H0.grad.sum(axis=1).abs()[subgraph].sum()\n",
    "\n",
    "        time_l.append(time.time()-time_a)\n",
    "\n",
    "        # CAM\n",
    "        time_a = time.time()\n",
    "        if masks is None:\n",
    "            masks = [1]*(len(nn.blocks)-1)\n",
    "        H0 = nn.ini(g.get_adj(), H0)\n",
    "        H = nn.blocks[0].forward(H0,torch.eye(H0.shape[0]).unsqueeze(0))\n",
    "        A = nn.adj(g.get_adj())\n",
    "        for l,mask in zip(nn.blocks[1:],masks):\n",
    "            H = l.forward(H,A,mask=mask)\n",
    "        # H = H.sum(dim=0) / 20**.5\n",
    "        score_cam = H[subgraph, g.label].abs().sum().data\n",
    "\n",
    "        time_l.append(time.time()-time_a)\n",
    "        time_ll.append(time_l)\n",
    "    time_stats.append([s_size] + np.array(time_ll).mean(axis=0).tolist())\n",
    "time_stats_df = pd.DataFrame(time_stats, columns=['s_size','naive','sGNN-LRP','GNNExplainer','Grad','CAM'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, gridspec_kw={'height_ratios': [2, 1, 1]}, figsize=(3.5,4))\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between axes\n",
    "ax1.yaxis.set_label_position(\"right\")\n",
    "ax2.yaxis.set_label_position(\"right\")\n",
    "ax3.yaxis.set_label_position(\"right\")\n",
    "\n",
    "plt.rc('legend', fontsize=12)\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['bottom'].set_visible(False)\n",
    "ax3.spines['top'].set_visible(False)\n",
    "\n",
    "ax3.set_xlabel(r'$|S|$')\n",
    "ax3.set_xticks(np.arange(1,20))\n",
    "ax3.set_xticklabels([str(i) if i % 2 != 0 else '' for i in range(1,20)])\n",
    "\n",
    "line1, = ax1.plot(time_stats_df['s_size'], time_stats_df['naive'], 'm:')\n",
    "line2, = ax1.plot(time_stats_df['s_size'], time_stats_df['sGNN-LRP'], 'r-')\n",
    "line3, = ax1.plot(time_stats_df['s_size'], time_stats_df['Grad'], 'b--')\n",
    "line4, = ax1.plot(time_stats_df['s_size'], time_stats_df['CAM'], 'y-.')\n",
    "line5, = ax1.plot(time_stats_df['s_size'], time_stats_df['GNNExplainer'], 'g-+')\n",
    "# ax1.legend(['naive GNN-LRP', 'sGNN-LRP', 'Gradient-based', '(Grad-)CAM', 'GNNExplainer'])\n",
    "\n",
    "line2.remove()\n",
    "line3.remove()\n",
    "line4.remove()\n",
    "line5.remove()\n",
    "\n",
    "ax2.plot(time_stats_df['s_size'], time_stats_df['GNNExplainer'], 'g-+')\n",
    "ax2.plot(time_stats_df['s_size'], time_stats_df['naive'], 'm:')\n",
    "\n",
    "# ax2.set_ylabel('Time (s)')\n",
    "ax3.plot(time_stats_df['s_size'], time_stats_df['naive'], 'm:')\n",
    "ax3.plot(time_stats_df['s_size'], time_stats_df['sGNN-LRP'], 'r-')\n",
    "ax3.plot(time_stats_df['s_size'], time_stats_df['Grad'], 'b--')\n",
    "ax3.plot(time_stats_df['s_size'], time_stats_df['CAM'], 'y-.')\n",
    "\n",
    "\n",
    "ax1.spines.bottom.set_visible(False)\n",
    "ax3.spines.top.set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "\n",
    "ax1.xaxis.set_visible(False)\n",
    "ax2.xaxis.set_visible(False)\n",
    "ax2.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "\n",
    "ax1.set_ylim(1.5)\n",
    "ax2.set_ylim(0.004,0.7)  # outliers only\n",
    "ax3.set_ylim(-0,0.004)\n",
    "\n",
    "d = .5  # proportion of vertical to horizontal extent of the slanted line\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12,\n",
    "              linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "ax1.plot([0, 1], [0, 0], transform=ax1.transAxes, **kwargs)\n",
    "ax2.plot([0, 1], [1, 1], transform=ax2.transAxes, **kwargs)\n",
    "ax2.plot([0, 1], [0, 0], transform=ax2.transAxes, **kwargs)\n",
    "ax3.plot([0, 1], [1, 1], transform=ax3.transAxes, **kwargs)\n",
    "plt.show()\n",
    "# plt.savefig('imgs/time_consumption_gnnexpl_etc_S.eps', dpi=600, format='eps', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## auac aupc on MUTAG and Graph-SST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,5))\n",
    "\n",
    "\n",
    "data_dir = 'evaluation_results/mutag_acti_result.txt'; dataset = 'mutag'\n",
    "data_dir1 = 'evaluation_results/gnnexpl_etc_auac_mutag.csv'; dataset = 'mutag'\n",
    "stat_df = pd.read_csv(data_dir1)\n",
    "\n",
    "with open(data_dir,'r') as f:\n",
    "    s = f.readlines()[2:]\n",
    "stats = {}\n",
    "for i in range(len(s)//2):\n",
    "    alpha = float(s[i * 2].split(',')[0].split(' ')[-1])\n",
    "    for sss in s[i * 2 + 1].split('\\n')[0].split('\\t')[1:]:\n",
    "        sss = sss.split(':')\n",
    "        if sss[0].strip() not in stats:\n",
    "            stats[sss[0].strip()] = []\n",
    "        stats[sss[0].strip()].append(float(sss[1]))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for key in stats.keys():\n",
    "    df[key] = stats[key]\n",
    "\n",
    "df['alpha'] = np.arange(0,1.01,0.05)\n",
    "df['method'] = 'sGNN-LRP'\n",
    "\n",
    "stat_df = stat_df.append(df)\n",
    "\n",
    "plt.subplot(241)\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'],stat_df[stat_df['method']=='sGNN-LRP']['auac_pos'], 'r-')\n",
    "plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'],stat_df[stat_df['method']=='Gradient-based']['auac_pos'], 'b--')\n",
    "plt.plot(stat_df[stat_df['method']=='CAM']['alpha'],stat_df[stat_df['method']=='CAM']['auac_pos'], 'y-.')\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'],stat_df[stat_df['method']=='GNNExplainer']['auac_pos'], 'g-+')\n",
    "\n",
    "opt_val_idx = stat_df[stat_df['method']=='sGNN-LRP']['auac_pos'].to_numpy().argsort()[-1]\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='sGNN-LRP']['auac_pos'].to_numpy()[opt_val_idx], 'r^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='Gradient-based']['auac_pos'].to_numpy().argsort()[-1]\n",
    "# plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='Gradient-based']['auac_pos'].to_numpy()[opt_val_idx], 'b^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='CAM']['auac_pos'].to_numpy().argsort()[-1]\n",
    "# plt.plot(stat_df[stat_df['method']=='CAM']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='CAM']['auac_pos'].to_numpy()[opt_val_idx], 'y^')\n",
    "opt_val_idx = stat_df[stat_df['method']=='GNNExplainer']['auac_pos'].to_numpy().argsort()[-1]\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='GNNExplainer']['auac_pos'].to_numpy()[opt_val_idx], 'g^')\n",
    "\n",
    "plt.xticks([])\n",
    "plt.title('MUTAG_positive')\n",
    "plt.ylabel('AUAC')\n",
    "plt.legend(['sGNN-LRP', 'Gradient-based', '(Grad-)CAM', 'GNNExplainer'])\n",
    "\n",
    "plt.subplot(242)\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'],stat_df[stat_df['method']=='sGNN-LRP']['auac_neg'], 'r-')\n",
    "plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'],stat_df[stat_df['method']=='Gradient-based']['auac_neg'], 'b--')\n",
    "plt.plot(stat_df[stat_df['method']=='CAM']['alpha'],stat_df[stat_df['method']=='CAM']['auac_neg'], 'y-.')\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'],stat_df[stat_df['method']=='GNNExplainer']['auac_neg'], 'g-+')\n",
    "\n",
    "opt_val_idx = stat_df[stat_df['method']=='sGNN-LRP']['auac_neg'].to_numpy().argsort()[-1]\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='sGNN-LRP']['auac_neg'].to_numpy()[opt_val_idx], 'r^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='Gradient-based']['auac_neg'].to_numpy().argsort()[-1]\n",
    "# plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='Gradient-based']['auac_neg'].to_numpy()[opt_val_idx], 'b^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='CAM']['auac_neg'].to_numpy().argsort()[-1]\n",
    "# plt.plot(stat_df[stat_df['method']=='CAM']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='CAM']['auac_neg'].to_numpy()[opt_val_idx], 'y^')\n",
    "opt_val_idx = stat_df[stat_df['method']=='GNNExplainer']['auac_neg'].to_numpy().argsort()[-1]\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='GNNExplainer']['auac_neg'].to_numpy()[opt_val_idx], 'g^')\n",
    "\n",
    "plt.xticks([])\n",
    "plt.title('MUTAG_negative')\n",
    "\n",
    "#########################################################################\n",
    "data_dir = 'evaluation_results/graphsst2_acti_result.txt'; dataset = 'graphsst2'\n",
    "data_dir1 = 'evaluation_results/gnnexpl_etc_auac_sst2.csv'; dataset = 'graphsst2'\n",
    "stat_df = pd.read_csv(data_dir1)\n",
    "\n",
    "with open(data_dir,'r') as f:\n",
    "    s = f.readlines()[2:]\n",
    "stats = {}\n",
    "for i in range(len(s)//2):\n",
    "    alpha = float(s[i * 2].split(',')[0].split(' ')[-1])\n",
    "    for sss in s[i * 2 + 1].split('\\n')[0].split('\\t')[1:]:\n",
    "        sss = sss.split(':')\n",
    "        if sss[0].strip() not in stats:\n",
    "            stats[sss[0].strip()] = []\n",
    "        stats[sss[0].strip()].append(float(sss[1]))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for key in stats.keys():\n",
    "    df[key] = stats[key]\n",
    "\n",
    "df['alpha'] = np.arange(0,1.01,0.05)\n",
    "df['method'] = 'sGNN-LRP'\n",
    "\n",
    "stat_df = stat_df.append(df)\n",
    "\n",
    "plt.subplot(243)\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'],stat_df[stat_df['method']=='sGNN-LRP']['auac_pos'], 'r-')\n",
    "plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'],stat_df[stat_df['method']=='Gradient-based']['auac_pos'], 'b--')\n",
    "plt.plot(stat_df[stat_df['method']=='CAM']['alpha'],stat_df[stat_df['method']=='CAM']['auac_pos'], 'y-.')\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'],stat_df[stat_df['method']=='GNNExplainer']['auac_pos'], 'g-+')\n",
    "\n",
    "opt_val_idx = stat_df[stat_df['method']=='sGNN-LRP']['auac_pos'].to_numpy().argsort()[-1]\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='sGNN-LRP']['auac_pos'].to_numpy()[opt_val_idx], 'r^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='Gradient-based']['auac_pos'].to_numpy().argsort()[-1]\n",
    "# plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='Gradient-based']['auac_pos'].to_numpy()[opt_val_idx], 'b^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='CAM']['auac_pos'].to_numpy().argsort()[-1]\n",
    "# plt.plot(stat_df[stat_df['method']=='CAM']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='CAM']['auac_pos'].to_numpy()[opt_val_idx], 'y^')\n",
    "opt_val_idx = stat_df[stat_df['method']=='GNNExplainer']['auac_pos'].to_numpy().argsort()[-1]\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='GNNExplainer']['auac_pos'].to_numpy()[opt_val_idx], 'g^')\n",
    "\n",
    "plt.xticks([])\n",
    "plt.title('Graph-SST2_positive')\n",
    "\n",
    "plt.subplot(244)\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'],stat_df[stat_df['method']=='sGNN-LRP']['auac_neg'], 'r-')\n",
    "plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'],stat_df[stat_df['method']=='Gradient-based']['auac_neg'], 'b--')\n",
    "plt.plot(stat_df[stat_df['method']=='CAM']['alpha'],stat_df[stat_df['method']=='CAM']['auac_neg'], 'y-.')\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'],stat_df[stat_df['method']=='GNNExplainer']['auac_neg'], 'g-+')\n",
    "\n",
    "opt_val_idx = stat_df[stat_df['method']=='sGNN-LRP']['auac_neg'].to_numpy().argsort()[-1]\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='sGNN-LRP']['auac_neg'].to_numpy()[opt_val_idx], 'r^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='Gradient-based']['auac_neg'].to_numpy().argsort()[-1]\n",
    "# plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='Gradient-based']['auac_neg'].to_numpy()[opt_val_idx], 'b^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='CAM']['auac_neg'].to_numpy().argsort()[-1]\n",
    "# plt.plot(stat_df[stat_df['method']=='CAM']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='CAM']['auac_neg'].to_numpy()[opt_val_idx], 'y^')\n",
    "opt_val_idx = stat_df[stat_df['method']=='GNNExplainer']['auac_neg'].to_numpy().argsort()[-1]\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='GNNExplainer']['auac_neg'].to_numpy()[opt_val_idx], 'g^')\n",
    "\n",
    "plt.xticks([])\n",
    "plt.title('Graph-SST2_negative')\n",
    "\n",
    "#########################################################################\n",
    "data_dir = 'evaluation_results/mutag_prun_result.txt'; dataset = 'mutag'\n",
    "data_dir1 = 'evaluation_results/gnnexpl_etc_aupc_mutag.csv'; dataset = 'mutag'\n",
    "stat_df = pd.read_csv(data_dir1)\n",
    "\n",
    "with open(data_dir,'r') as f:\n",
    "    s = f.readlines()[2:]\n",
    "stats = {}\n",
    "for i in range(len(s)//2):\n",
    "    alpha = float(s[i * 2].split(',')[0].split(' ')[-1])\n",
    "    for sss in s[i * 2 + 1].split('\\n')[0].split('\\t')[1:]:\n",
    "        sss = sss.split(':')\n",
    "        if sss[0].strip() not in stats:\n",
    "            stats[sss[0].strip()] = []\n",
    "        stats[sss[0].strip()].append(float(sss[1]))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for key in stats.keys():\n",
    "    df[key] = stats[key]\n",
    "\n",
    "df['alpha'] = np.arange(0,1.01,0.05)\n",
    "df['method'] = 'sGNN-LRP'\n",
    "\n",
    "stat_df = stat_df.append(df)\n",
    "\n",
    "plt.subplot(245)\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'],stat_df[stat_df['method']=='sGNN-LRP']['aupc_pos'], 'r-')\n",
    "plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'],stat_df[stat_df['method']=='Gradient-based']['aupc_pos'], 'b--')\n",
    "plt.plot(stat_df[stat_df['method']=='CAM']['alpha'],stat_df[stat_df['method']=='CAM']['aupc_pos'], 'y-.')\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'],stat_df[stat_df['method']=='GNNExplainer']['aupc_pos'], 'g-+')\n",
    "\n",
    "opt_val_idx = stat_df[stat_df['method']=='sGNN-LRP']['aupc_pos'].to_numpy().argsort()[0]\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='sGNN-LRP']['aupc_pos'].to_numpy()[opt_val_idx], 'r^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='Gradient-based']['aupc_pos'].to_numpy().argsort()[0]\n",
    "# plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='Gradient-based']['aupc_pos'].to_numpy()[opt_val_idx], 'b^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='CAM']['aupc_pos'].to_numpy().argsort()[0]\n",
    "# plt.plot(stat_df[stat_df['method']=='CAM']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='CAM']['aupc_pos'].to_numpy()[opt_val_idx], 'y^')\n",
    "opt_val_idx = stat_df[stat_df['method']=='GNNExplainer']['aupc_pos'].to_numpy().argsort()[0]\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='GNNExplainer']['aupc_pos'].to_numpy()[opt_val_idx], 'g^')\n",
    "\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel('AUPC')\n",
    "plt.title('MUTAG_positive')\n",
    "\n",
    "plt.subplot(246)\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'],stat_df[stat_df['method']=='sGNN-LRP']['aupc_neg'], 'r-')\n",
    "plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'],stat_df[stat_df['method']=='Gradient-based']['aupc_neg'], 'b--')\n",
    "plt.plot(stat_df[stat_df['method']=='CAM']['alpha'],stat_df[stat_df['method']=='CAM']['aupc_neg'], 'y-.')\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'],stat_df[stat_df['method']=='GNNExplainer']['aupc_neg'], 'g-+')\n",
    "\n",
    "opt_val_idx = stat_df[stat_df['method']=='sGNN-LRP']['aupc_neg'].to_numpy().argsort()[0]\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='sGNN-LRP']['aupc_neg'].to_numpy()[opt_val_idx], 'r^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='Gradient-based']['aupc_neg'].to_numpy().argsort()[0]\n",
    "# plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='Gradient-based']['aupc_neg'].to_numpy()[opt_val_idx], 'b^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='CAM']['aupc_neg'].to_numpy().argsort()[0]\n",
    "# plt.plot(stat_df[stat_df['method']=='CAM']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='CAM']['aupc_neg'].to_numpy()[opt_val_idx], 'y^')\n",
    "opt_val_idx = stat_df[stat_df['method']=='GNNExplainer']['aupc_neg'].to_numpy().argsort()[0]\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='GNNExplainer']['aupc_neg'].to_numpy()[opt_val_idx], 'g^')\n",
    "\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.title('MUTAG_negative')\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "data_dir = 'evaluation_results/graphsst2_prun_result.txt'; dataset = 'graphsst2'\n",
    "data_dir1 = 'evaluation_results/gnnexpl_etc_aupc_sst2.csv'; dataset = 'graphsst2'\n",
    "stat_df = pd.read_csv(data_dir1)\n",
    "\n",
    "with open(data_dir,'r') as f:\n",
    "    s = f.readlines()[2:]\n",
    "stats = {}\n",
    "for i in range(len(s)//2):\n",
    "    alpha = float(s[i * 2].split(',')[0].split(' ')[-1])\n",
    "    for sss in s[i * 2 + 1].split('\\n')[0].split('\\t')[1:]:\n",
    "        sss = sss.split(':')\n",
    "        if sss[0].strip() not in stats:\n",
    "            stats[sss[0].strip()] = []\n",
    "        stats[sss[0].strip()].append(float(sss[1]))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for key in stats.keys():\n",
    "    df[key] = stats[key]\n",
    "\n",
    "df['alpha'] = np.arange(0,1.01,0.05)\n",
    "df['method'] = 'sGNN-LRP'\n",
    "\n",
    "stat_df = stat_df.append(df)\n",
    "\n",
    "plt.subplot(247)\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'],stat_df[stat_df['method']=='sGNN-LRP']['aupc_pos'], 'r-')\n",
    "plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'],stat_df[stat_df['method']=='Gradient-based']['aupc_pos'], 'b--')\n",
    "plt.plot(stat_df[stat_df['method']=='CAM']['alpha'],stat_df[stat_df['method']=='CAM']['aupc_pos'], 'y-.')\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'],stat_df[stat_df['method']=='GNNExplainer']['aupc_pos'], 'g-+')\n",
    "\n",
    "opt_val_idx = stat_df[stat_df['method']=='sGNN-LRP']['aupc_pos'].to_numpy().argsort()[0]\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='sGNN-LRP']['aupc_pos'].to_numpy()[opt_val_idx], 'r^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='Gradient-based']['aupc_pos'].to_numpy().argsort()[0]\n",
    "# plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='Gradient-based']['aupc_pos'].to_numpy()[opt_val_idx], 'b^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='CAM']['aupc_pos'].to_numpy().argsort()[0]\n",
    "# plt.plot(stat_df[stat_df['method']=='CAM']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='CAM']['aupc_pos'].to_numpy()[opt_val_idx], 'y^')\n",
    "opt_val_idx = stat_df[stat_df['method']=='GNNExplainer']['aupc_pos'].to_numpy().argsort()[0]\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='GNNExplainer']['aupc_pos'].to_numpy()[opt_val_idx], 'g^')\n",
    "\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.title('Graph-SST2_positive')\n",
    "\n",
    "plt.subplot(248)\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'],stat_df[stat_df['method']=='sGNN-LRP']['aupc_neg'], 'r-')\n",
    "plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'],stat_df[stat_df['method']=='Gradient-based']['aupc_neg'], 'b--')\n",
    "plt.plot(stat_df[stat_df['method']=='CAM']['alpha'],stat_df[stat_df['method']=='CAM']['aupc_neg'], 'y-.')\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'],stat_df[stat_df['method']=='GNNExplainer']['aupc_neg'], 'g-+')\n",
    "\n",
    "opt_val_idx = stat_df[stat_df['method']=='sGNN-LRP']['aupc_neg'].to_numpy().argsort()[0]\n",
    "plt.plot(stat_df[stat_df['method']=='sGNN-LRP']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='sGNN-LRP']['aupc_neg'].to_numpy()[opt_val_idx], 'r^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='Gradient-based']['aupc_neg'].to_numpy().argsort()[0]\n",
    "# plt.plot(stat_df[stat_df['method']=='Gradient-based']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='Gradient-based']['aupc_neg'].to_numpy()[opt_val_idx], 'b^')\n",
    "# opt_val_idx = stat_df[stat_df['method']=='CAM']['aupc_neg'].to_numpy().argsort()[0]\n",
    "# plt.plot(stat_df[stat_df['method']=='CAM']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='CAM']['aupc_neg'].to_numpy()[opt_val_idx], 'y^')\n",
    "opt_val_idx = stat_df[stat_df['method']=='GNNExplainer']['aupc_neg'].to_numpy().argsort()[0]\n",
    "plt.plot(stat_df[stat_df['method']=='GNNExplainer']['alpha'].to_numpy()[opt_val_idx],stat_df[stat_df['method']=='GNNExplainer']['aupc_neg'].to_numpy()[opt_val_idx], 'g^')\n",
    "\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.title('Graph-SST2_negative')\n",
    "plt.savefig('imgs/gnnexpl_etc_aupc_auac.eps', dpi=600, format='eps', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65d5eb093fbec7e7bc52665d82a3cd76b3638a6de4797644d5d4a8277e42c4dc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sGNN-LRP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
